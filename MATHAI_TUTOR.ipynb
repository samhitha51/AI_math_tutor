{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Math AI Tutor\n",
        "\n",
        "Welcome to the Math AI Tutor notebook! In this tutorial, we'll explore how to create a simple AI tutor that can help with basic math problems. This tutor will be able to perform arithmetic operations such as addition, subtraction, multiplication, and division, as well as provide explanations for each step.\n",
        "\n",
        "We'll start by defining functions for each arithmetic operation and then implement a user interface where users can input math problems. The tutor will then solve the problems step by step, providing explanations along the way.\n",
        "\n",
        "Let's get started!\n"
      ],
      "metadata": {
        "id": "Lx16hifbbqmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploring ChatGPT APIs**\n",
        "\n",
        "In this tutorial, we'll delve into the functionalities of the `chat.completions()` API endpoints provided by ChatGPT. These endpoints are incredibly versatile, allowing us to generate one-off responses and conduct interactive chats or conversations. Throughout this session, we'll focus on:\n",
        "\n",
        "1. Making API calls to the `chat.completions()` endpoints.\n",
        "2. Enhancing prompts to handle more nuanced inputs for accomplishing complex tasks.\n",
        "3. Building a basic 'AI Tutor' application leveraging the capabilities of the `chat.completions()` endpoint.\n",
        "\n",
        "### Getting Started with the `chat.completions()` API in Python\n",
        "\n",
        "To begin, we need to set up the `openai` Python library. If you're using Google Colab, you can install libraries by prefixing `pip` with an exclamation mark, like so: `!pip install <library_name>`. Additionally, ensure you have obtained an OpenAI API key.\n"
      ],
      "metadata": {
        "id": "blnCMTi-b_qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install openai\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "moJyTKPwzGay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e116a31-361b-48fb-c370-f45bd4b2a0b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/226.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive allows us to access files stored in Google Drive within the Colab notebook.\n",
        "# Importing the necessary module from Google Colab.\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounting Google Drive to '/content/drive' directory in the Colab environment.\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asFqqSzwcmrn",
        "outputId": "cf581057-bfbb-4b47-8a76-39599c5af514"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path where the data is located in Google Drive.\n",
        "filepath = '/content/drive/MyDrive/Gen_AI/'\n",
        "\n",
        "# Utilizing the Linux command 'ls' to list all files in the specified directory.\n",
        "# This command is executed using the '!' symbol in Colab notebooks.\n",
        "!ls \"/content/drive/MyDrive/Gen_AI/\"\n",
        "\n",
        "# Alternatively, you can use the filepath variable to reference the directory.\n",
        "# Uncomment the line below if you prefer using the variable.\n",
        "# !ls $filepath\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGscQrIUxdw6",
        "outputId": "7edc03f4-300d-4675-e09b-772d93b58c05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI_tutor_system_message_1.txt  GPT_API_key.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the openai library to utilize its functionalities.\n",
        "import openai\n",
        "\n",
        "# Define the file path where the API key is stored.\n",
        "filepath = \"/content/drive/My Drive/Gen_AI/\"\n",
        "\n",
        "# Read the content of the .txt file containing the API key.\n",
        "with open(filepath + \"GPT_API_key.txt\", \"r\") as f:\n",
        "    # Read the API key and strip any leading or trailing whitespace.\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "# Set the API key retrieved from the file.\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Uncomment the line below if you want to print the API key for verification.\n",
        "# print(\"API Key:\", api_key)\n"
      ],
      "metadata": {
        "id": "YR9TsSe-F38D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working With OpenAI's `chat.completions()` API\n",
        "\n",
        "With OpenAI's APIs, we gain access to powerful natural language processing capabilities. Specifically, the `chat.completions()` endpoint offers chat completion functionality, allowing for interactive conversations with AI models like GPT-3, 3.5, or 4.\n",
        "\n",
        "For detailed information on using this API, refer to the [official API documentation](https://platform.openai.com/docs/guides/text-generation). Here's a brief overview of key parameters:\n",
        "- We typically use the model `gpt-3.5-turbo` within the GPT-3.5 family.\n",
        "- `max_tokens` specifies the maximum number of tokens to generate.\n",
        "- `temperature` ranges from 0 (deterministic) to 2 (random) and defaults to 1.\n",
        "\n",
        "To utilize the `chat.completions()` API effectively, we must define three main roles:\n",
        "1. **System**: Sets the behavior of the assistant.\n",
        "2. **User**: Represents the end user interacting with the chatbot.\n",
        "3. **Assistant**: Refers to the ChatGPT chatbot itself.\n",
        "\n",
        "An API call structure involves providing system instructions, user input, and assistant responses within a conversation history list. Subsequent API calls build upon this history.\n",
        "\n",
        "The API response contains a dictionary-like object, including `total_tokens` used. We extract the response text from `choices`, which is a list.\n",
        "\n",
        "### Creating More Complex Prompts\n",
        "\n",
        "We can enhance prompts to accept user inputs, facilitating more dynamic interactions. For example, allowing users to specify topics.\n",
        "\n",
        "### Multi-Turn Conversation using `chat.completions()`: Math AI Tutor\n",
        "\n",
        "In this section, we leverage the `chat.completions()` endpoint to create a math AI tutor application. Such an application engages in multi-turn conversations, providing assistance to students with math problems.\n",
        "\n",
        "A good tutor doesn't simply provide answers but guides students through problem-solving steps, offering hints and feedback. This necessitates contextual awareness and coherent conversations, precisely what the `chat.completions()` API enables.\n",
        "\n",
        "An illustrative conversation could involve the student seeking help with a math equation and the tutor guiding them through problem-solving steps, ensuring a meaningful learning experience.\n",
        "\n"
      ],
      "metadata": {
        "id": "TxGPIElGdrHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<hr>\n",
        "\n",
        "An example (good) conversation may look like this:\n",
        "* Student: Help me solve the equation x^2 - 5x + 6 = 0\n",
        "* Tutor: Sure. Which step of the solution have you reached?\n",
        "* Student: Can you tell me the answer first?\n",
        "* Tutor: As a tutor, I can help you solve the problem by providing guidance, hints or feedback. But I cannot reveal the answer since it will jeopardize your learning.\n",
        "* Student: Okay. What should be my first step to solve this equation?\n",
        "* Tutor: Try to factorize the equation, i.e. break it down in the form (x - a)(x - b) = 0.\n"
      ],
      "metadata": {
        "id": "OPNxny4TbY3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple API call to the `chat.completions.create()` method.\n",
        "# This call initiates a conversation between the user and the AI tutor.\n",
        "\n",
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI tutor that assists school students with math homework problems.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Help me solve the equation 3x - 9 = 21.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Try moving the 9 to the right-hand side of the equation. What do you get?\"},\n",
        "        {\"role\": \"user\", \"content\": \"3x = 12\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the API response containing the chat completion.\n",
        "chat_response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWeH5bHPbaDE",
        "outputId": "246988f8-4a42-4366-a339-26d8c66473ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8tOiTDNcrUblo1J9ZgEKc3JsNMOXb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To solve for x, divide both sides of the equation by 3. What is your final answer for x?', role='assistant', function_call=None, tool_calls=None))], created=1708213741, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_69829325d0', usage=CompletionUsage(completion_tokens=23, prompt_tokens=72, total_tokens=95))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting only the text from the API response.\n",
        "# We print the content of the message from the first choice.\n",
        "\n",
        "print(chat_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCUyDYOsoRAR",
        "outputId": "1a685999-69e1-45f8-957d-c03f9d62343b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve for x, divide both sides of the equation by 3. What is your final answer for x?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding complex initial system message\n",
        "# Reading the content of the file \"AI_tutor_system_message_1.txt\" and storing it in the variable `system_message`.\n",
        "# We join the lines read from the file into a single string.\n",
        "\n",
        "with open(filepath + \"AI_tutor_system_message_1.txt\", \"r\") as f:\n",
        "    system_message = ' '.join(f.readlines())\n",
        "\n",
        "# Printing the content of the system message.\n",
        "print(system_message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-su8buzduX",
        "outputId": "1b6ee0a6-d9ef-4f01-eb2c-cb542ddce500"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an AI tutor that assists school students with math homework problems. You never reveal the right answer to the student. You ask probing questions to identify where the student might be needing help, provide hints and guidance, and provide directional feedback to indicate if the student is moving in the right direction.Do not reveal the correct answer to the student.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should note that the `system_message` has its limitations - while it sets the behavior of the bot to an extent, it may not completely determine the behavior. To solve for this, we can provide some examples to the bot - this is called **few shot prompting**.\n",
        "\n",
        "### Few-Shot Prompting | Providing Examples\n",
        "Few-shot prompting is the technique of providing examples of behaviours that we expect from the bot. Let's create a list with certain examples which acts as the `messages` object."
      ],
      "metadata": {
        "id": "gWCFSYxd0AH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a list containing the conversation history with system messages, user inputs, and assistant responses.\n",
        "\n",
        "message_history = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": \"Help me solve the equation 3x - 9 = 21.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Sure! Try moving the 9 to the right-hand side of the equation. What do you get?\"},\n",
        "    {\"role\": \"user\", \"content\": \"3x = 12\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Well, there seems to be a mistake. When you move 9 to the right-hand side, you need to change its sign. Can you try again?\"},\n",
        "    {\"role\": \"user\", \"content\": \"3x = 30\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"That looks good, great job! Now, try to divide both sides by 3. What do you get?\"},\n",
        "    {\"role\": \"user\", \"content\": \"x = 10\"},\n",
        "]"
      ],
      "metadata": {
        "id": "OWa1Fq4m0TTU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requesting the chatbot's next response based on the provided message history.\n",
        "\n",
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=message_history\n",
        ")\n",
        "\n",
        "# Printing the content of the chatbot's response.\n",
        "print(chat_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Q36IW71gwH",
        "outputId": "b141fed6-1e72-4e0f-9652-2fba610cf2c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great work! You successfully solved for x. Keep in mind to always check your work by substituting your solution back into the original equation to ensure it balances out. If you have any more questions or need further assistance, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build a mini-program where we can input the message as an actual user / student and test our AI tutor. But notice that there is one small problem - the examples we have provided are **examples**, not actual conversations that the chatbot should refer to. To clarify that, we can specify the key `name`to `example_user` and `example_assistant`."
      ],
      "metadata": {
        "id": "EraP5lfx3AyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a list containing the conversation history with system messages, user inputs, and assistant responses.\n",
        "# Each message includes the role of the sender and the content of the message.\n",
        "\n",
        "message_history = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"Help me solve the equation 3x - 9 = 21.\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Sure! Try moving the 9 to the right-hand side of the equation. What do you get?\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"3x = 12\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Well, there seems to be a mistake. When you move 9 to the right-hand side, you need to change its sign. Can you try again?\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"3x = 30\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"That looks good, great job! Now, try to divide both sides by 3. What do you get?\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"x = 10\"},\n",
        "    {\"role\": \"user\", \"content\": \"Help me solve the equation x - 10 = 2x\"}\n",
        "]"
      ],
      "metadata": {
        "id": "8o9SB6sH2pMJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requesting the chatbot's next response based on the provided message history.\n",
        "\n",
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=message_history\n",
        ")\n",
        "\n",
        "# Printing the content of the chatbot's response.\n",
        "print(chat_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dg5QPt44_qm",
        "outputId": "ebc25da9-4bd7-4092-861d-6e6ad5a23488"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve this equation, the first step is to simplify the equation by isolating the variable terms on one side of the equation. Could you try to rearrange the terms and tell me what you get?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build a mini program which can take inputs so we can chat with our AI tutor and test it. The system message and some initial examples  are provided in `message_history` already.\n",
        "\n",
        "Let's  write a program which starts with the initial examples, can run a conversation of length n (we need to stop the program somewhere!), add a field which can take the user's input and append it to the `message_history`."
      ],
      "metadata": {
        "id": "UGPTAZMw5Mj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AI Tutor Mini Program\n",
        "# Enter \"exit\" to terminate the program\n",
        "\n",
        "import openai\n",
        "\n",
        "# Initialize system message, user, and assistant examples\n",
        "message_history = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"Help me solve the equation 3x - 9 = 21.\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Sure! Try moving the 9 to the right-hand side of the equation. What do you get?\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"3x = 12\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Well, there seems to be a mistake. When you move 9 to the right-hand side, you need to change its sign. Can you try again?\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"3x = 30\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"That looks good, great job! Now, try to divide both sides by 3. What do you get?\"},\n",
        "    {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"x = 10\"}\n",
        "]\n",
        "\n",
        "# Set maximum number of conversations and initialize conversation length\n",
        "max_conversations = 20\n",
        "conversation_length = 0\n",
        "\n",
        "# Main loop for engaging in conversations\n",
        "while conversation_length < max_conversations:\n",
        "    # Get user input\n",
        "    user_input = input(\"Your question or input: \")\n",
        "\n",
        "    # Exit if user enters \"exit\"\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"AI Tutor: Exiting the program!\")\n",
        "        break\n",
        "\n",
        "    # Add user input to message history\n",
        "    message_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get AI response using OpenAI's API\n",
        "    chat_response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=message_history\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # Print AI response\n",
        "    print(\"\\nAI Tutor:\")\n",
        "    print(chat_response)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Add AI response to message history\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": chat_response})\n",
        "\n",
        "    # Increment conversation length\n",
        "    conversation_length += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhx0XCjx5BN9",
        "outputId": "2f2e2cc7-e427-400c-87fa-ba315304f756"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your question or input: There is a set of 10 cards numbered [6, 5, 3, 9, 7, 6, 4, 2, 8, 2]. Alice randomly picks one card from the set. What is the probability of the card being greater than 5?\n",
            "\n",
            "AI Tutor:\n",
            "To find the probability of the card being greater than 5, we first need to count the total number of cards in the set that are greater than 5. Can you identify how many cards in the set have a value greater than 5?\n",
            "\n",
            "\n",
            "Your question or input: 4\n",
            "\n",
            "AI Tutor:\n",
            "Good job! Now, what is the total number of cards in the set?\n",
            "\n",
            "\n",
            "Your question or input: 10\n",
            "\n",
            "AI Tutor:\n",
            "Great! Now, to find the probability of picking a card greater than 5, you should divide the number of favorable outcomes (cards greater than 5) by the total number of possible outcomes (total number of cards in the set). Can you calculate the probability now?\n",
            "\n",
            "\n",
            "Your question or input: 4/10?\n",
            "\n",
            "AI Tutor:\n",
            "Correct! The probability of picking a card greater than 5 is 4/10. This can also be simplified to 2/5. Well done!\n",
            "\n",
            "\n",
            "Your question or input: thank you\n",
            "\n",
            "AI Tutor:\n",
            "You're welcome! If you have any more questions or need further assistance, feel free to ask. Good luck with your math problems!\n",
            "\n",
            "\n",
            "Your question or input: exit\n",
            "AI Tutor: Exiting the program!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations and Recommendations for the AI Tutor Application\n",
        "\n",
        "After developing a simple AI tutor application, it's evident that while it provides assistance, it's not without its flaws. Here are some key observations and recommendations:\n",
        "\n",
        "### Observations:\n",
        "- The AI tutor application, in its initial version, is prone to making mistakes, such as revealing correct answers and factual errors.\n",
        "- Testing the application with examples or tasks of varying complexity levels highlights these shortcomings.\n",
        "- The quality of responses can be influenced by factors like system instructions, available examples, prompt design techniques, and model fine-tuning.\n",
        "\n",
        "### Recommendations:\n",
        "- **Testing with Varied Examples:** Continue testing the application with diverse examples to understand its limitations and areas for improvement.\n",
        "- **Refinement of System Instructions:** Consider refining system instructions to provide clearer guidance to the AI tutor on its role and limitations.\n",
        "- **Enhanced Prompt Design:** Experiment with nuanced prompt design techniques to influence the AI tutor's responses. This may involve providing more contextual examples, exploring alternative prompting strategies, and refining few-shot prompting.\n",
        "- **Potential Model Fine-Tuning:** Depending on available resources and data, explore the possibility of fine-tuning the model with additional training data to improve performance over time.\n",
        "\n",
        "It's important to recognize that there's no one-size-fits-all solution to improving the AI tutor application. Continued experimentation and refinement based on observed results will be key to enhancing its effectiveness.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLMQZ51B9QUU"
      }
    }
  ]
}